{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c60b63",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis - Brent Oil Prices\n",
    "\n",
    "**Project:** Bayesian Change Point Analysis of Brent Oil Prices  \n",
    "**Organization:** Birhan Energies  \n",
    "**Date:** February 5, 2026\n",
    "\n",
    "## Objective\n",
    "Perform comprehensive exploratory data analysis to understand the properties of Brent oil price time series before applying Bayesian change point detection models.\n",
    "\n",
    "### Key Questions:\n",
    "1. What are the trends in Brent oil prices over time?\n",
    "2. Is the price series stationary or does it require transformation?\n",
    "3. What volatility patterns exist in the data?\n",
    "4. How should these properties inform our modeling choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2f99a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124066de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Figures will be saved to: c:\\Users\\Bekam\\Desktop\\acadamy 10\\bayesian-oil-market-insights\\notebooks\\..\\reports\\figures\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical tests\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import stats\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create reports directory\n",
    "REPORTS_DIR = Path('../reports/figures')\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Figures will be saved to: {REPORTS_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1fedb",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c248d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9011, 2)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20-May-87</td>\n",
       "      <td>18.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21-May-87</td>\n",
       "      <td>18.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-May-87</td>\n",
       "      <td>18.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-May-87</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26-May-87</td>\n",
       "      <td>18.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27-May-87</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28-May-87</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29-May-87</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01-Jun-87</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02-Jun-87</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Price\n",
       "0  20-May-87  18.63\n",
       "1  21-May-87  18.45\n",
       "2  22-May-87  18.55\n",
       "3  25-May-87  18.60\n",
       "4  26-May-87  18.63\n",
       "5  27-May-87  18.60\n",
       "6  28-May-87  18.60\n",
       "7  29-May-87  18.58\n",
       "8  01-Jun-87  18.65\n",
       "9  02-Jun-87  18.68"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Brent oil prices\n",
    "df = pd.read_csv('../data/BrentOilPrices.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aeea86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 9011 entries, 0 to 9010\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    9011 non-null   str    \n",
      " 1   Price   9011 non-null   float64\n",
      "dtypes: float64(1), str(1)\n",
      "memory usage: 140.9 KB\n",
      "None\n",
      "\n",
      "Basic Statistics:\n",
      "             Price\n",
      "count  9011.000000\n",
      "mean     48.420782\n",
      "std      32.860110\n",
      "min       9.100000\n",
      "25%      19.050000\n",
      "50%      38.570000\n",
      "75%      70.090000\n",
      "max     143.950000\n"
     ]
    }
   ],
   "source": [
    "# Check data info\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a57157",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"Apr 22, 2020\" doesn't match format \"%d-%b-%y\". You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert Date column to datetime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The dates are in format like '20-May-87'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mb-\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Sort by date\u001b[39;00m\n\u001b[32m      6\u001b[39m df = df.sort_values(\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bekam\\Desktop\\acadamy 10\\bayesian-oil-market-insights\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1040\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, origin, cache)\u001b[39m\n\u001b[32m   1038\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bekam\\Desktop\\acadamy 10\\bayesian-oil-market-insights\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bekam\\Desktop\\acadamy 10\\bayesian-oil-market-insights\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:470\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    460\u001b[39m     arg,\n\u001b[32m    461\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    465\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    466\u001b[39m ) -> Index:\n\u001b[32m    467\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    472\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:563\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:511\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:617\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"Apr 22, 2020\" doesn't match format \"%d-%b-%y\". You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "# Handle mixed date formats in the CSV\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Set Date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Total days: {len(df)}\")\n",
    "print(f\"\\nFirst and last entries:\")\n",
    "print(df.head(3))\n",
    "print(\"...\")\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df['Price'].isna().sum()\n",
    "print(f\"Missing values: {missing_values}\")\n",
    "\n",
    "if missing_values > 0:\n",
    "    print(f\"Percentage missing: {missing_values/len(df)*100:.2f}%\")\n",
    "    # Forward fill missing values if any\n",
    "    df['Price'].fillna(method='ffill', inplace=True)\n",
    "    print(\"Missing values filled using forward fill method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d1927",
   "metadata": {},
   "source": [
    "## 3. Visual Inspection: Raw Price Series\n",
    "\n",
    "First, let's visualize the entire price history to identify major trends, shocks, and structural breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot full time series\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "ax.plot(df.index, df['Price'], linewidth=0.8, color='steelblue')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Brent Oil Price (USD/barrel)', fontsize=12)\n",
    "ax.set_title('Brent Oil Prices: May 1987 - September 2022', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations for major visible events\n",
    "ax.axvline(pd.Timestamp('2008-07-11'), color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.text(pd.Timestamp('2008-07-11'), 140, '2008 Peak', rotation=90, verticalalignment='bottom')\n",
    "\n",
    "ax.axvline(pd.Timestamp('2020-04-20'), color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.text(pd.Timestamp('2020-04-20'), 80, 'COVID Crash', rotation=90, verticalalignment='bottom')\n",
    "\n",
    "ax.axvline(pd.Timestamp('2014-06-01'), color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.text(pd.Timestamp('2014-06-01'), 110, '2014 Oil Crash', rotation=90, verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '01_brent_oil_prices_full_series.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"- Price range: ${df['Price'].min():.2f} to ${df['Price'].max():.2f}\")\n",
    "print(f\"- Mean price: ${df['Price'].mean():.2f}\")\n",
    "print(f\"- Median price: ${df['Price'].median():.2f}\")\n",
    "print(f\"- Standard deviation: ${df['Price'].std():.2f}\")\n",
    "print(f\"âœ“ Figure saved: 01_brent_oil_prices_full_series.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7834df",
   "metadata": {},
   "source": [
    "## 4. Trend Analysis\n",
    "\n",
    "Calculate moving averages to identify long-term trends and smoothing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate moving averages\n",
    "df['MA_30'] = df['Price'].rolling(window=30).mean()\n",
    "df['MA_90'] = df['Price'].rolling(window=90).mean()\n",
    "df['MA_365'] = df['Price'].rolling(window=365).mean()\n",
    "\n",
    "# Plot with moving averages\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "ax.plot(df.index, df['Price'], linewidth=0.5, alpha=0.5, label='Daily Price', color='lightgray')\n",
    "ax.plot(df.index, df['MA_30'], linewidth=1.5, label='30-Day MA', color='blue')\n",
    "ax.plot(df.index, df['MA_90'], linewidth=1.5, label='90-Day MA', color='orange')\n",
    "ax.plot(df.index, df['MA_365'], linewidth=2, label='365-Day MA', color='red')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Brent Oil Price (USD/barrel)', fontsize=12)\n",
    "ax.set_title('Brent Oil Prices with Moving Averages', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '02_moving_averages.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Trend Insights:\")\n",
    "print(\"- Multiple regime shifts visible in long-term moving average\")\n",
    "print(\"- High volatility periods clearly distinguishable\")\n",
    "print(\"- Non-stationary behavior evident from changing mean levels\")\n",
    "print(f\"âœ“ Figure saved: 02_moving_averages.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5274270",
   "metadata": {},
   "source": [
    "## 5. Stationarity Testing\n",
    "\n",
    "Use the Augmented Dickey-Fuller (ADF) test to formally test for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9bb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test for stationarity\n",
    "    \n",
    "    Null Hypothesis (H0): Series has a unit root (non-stationary)\n",
    "    Alternative Hypothesis (H1): Series is stationary\n",
    "    \"\"\"\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    \n",
    "    print(f'\\n=== ADF Test Results: {name} ===')\n",
    "    print(f'ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print(f'Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'  {key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"\\nâœ“ Conclusion: Reject H0 - Series is STATIONARY (p-value = {result[1]:.6f})\")\n",
    "    else:\n",
    "        print(f\"\\nâœ— Conclusion: Fail to reject H0 - Series is NON-STATIONARY (p-value = {result[1]:.6f})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test raw prices\n",
    "adf_result_price = adf_test(df['Price'], 'Raw Prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b011225",
   "metadata": {},
   "source": [
    "## 6. Log Returns Calculation\n",
    "\n",
    "Calculate log returns to potentially achieve stationarity:  \n",
    "$$r_t = \\log(P_t) - \\log(P_{t-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "df['Log_Price'] = np.log(df['Price'])\n",
    "df['Log_Returns'] = df['Log_Price'].diff()\n",
    "\n",
    "# Also calculate simple returns for comparison\n",
    "df['Simple_Returns'] = df['Price'].pct_change()\n",
    "\n",
    "print(\"Log Returns Statistics:\")\n",
    "print(df['Log_Returns'].describe())\n",
    "\n",
    "# Test log returns for stationarity\n",
    "adf_result_returns = adf_test(df['Log_Returns'], 'Log Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize log returns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Log returns over time\n",
    "axes[0].plot(df.index, df['Log_Returns'], linewidth=0.5, color='darkblue', alpha=0.7)\n",
    "axes[0].axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0].set_xlabel('Date', fontsize=11)\n",
    "axes[0].set_ylabel('Log Returns', fontsize=11)\n",
    "axes[0].set_title('Daily Log Returns of Brent Oil Prices', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution of log returns\n",
    "axes[1].hist(df['Log_Returns'].dropna(), bins=100, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(df['Log_Returns'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Log_Returns\"].mean():.6f}')\n",
    "axes[1].axvline(df['Log_Returns'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"Log_Returns\"].median():.6f}')\n",
    "axes[1].set_xlabel('Log Returns', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Distribution of Log Returns', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '03_log_returns_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ“ Figure saved: 03_log_returns_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8438b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for normality of log returns\n",
    "from scipy.stats import shapiro, jarque_bera\n",
    "\n",
    "returns_clean = df['Log_Returns'].dropna()\n",
    "\n",
    "# Jarque-Bera test (better for large samples)\n",
    "jb_stat, jb_pvalue = jarque_bera(returns_clean)\n",
    "\n",
    "print(\"\\n=== Normality Test for Log Returns ===\")\n",
    "print(f\"Jarque-Bera Statistic: {jb_stat:.4f}\")\n",
    "print(f\"p-value: {jb_pvalue:.6f}\")\n",
    "\n",
    "if jb_pvalue > 0.05:\n",
    "    print(\"âœ“ Log returns appear normally distributed (p > 0.05)\")\n",
    "else:\n",
    "    print(\"âœ— Log returns deviate from normality (p < 0.05)\")\n",
    "    print(\"  This suggests heavy tails or skewness - common in financial data\")\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "print(f\"\\nSkewness: {stats.skew(returns_clean):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(returns_clean):.4f}\")\n",
    "print(\"\\nNote: Kurtosis > 0 indicates heavy tails (more extreme values than normal distribution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339bb697",
   "metadata": {},
   "source": [
    "## 7. Volatility Analysis\n",
    "\n",
    "Examine volatility patterns including volatility clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling volatility (standard deviation of returns)\n",
    "df['Volatility_30'] = df['Log_Returns'].rolling(window=30).std()\n",
    "df['Volatility_90'] = df['Log_Returns'].rolling(window=90).std()\n",
    "\n",
    "# Plot volatility over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Price and volatility\n",
    "axes[0].plot(df.index, df['Price'], linewidth=0.8, color='steelblue')\n",
    "axes[0].set_xlabel('Date', fontsize=11)\n",
    "axes[0].set_ylabel('Price (USD/barrel)', fontsize=11)\n",
    "axes[0].set_title('Brent Oil Prices', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling volatility\n",
    "axes[1].plot(df.index, df['Volatility_30'], linewidth=1, label='30-Day Volatility', color='orange', alpha=0.7)\n",
    "axes[1].plot(df.index, df['Volatility_90'], linewidth=1.5, label='90-Day Volatility', color='red')\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Volatility (Std Dev of Returns)', fontsize=11)\n",
    "axes[1].set_title('Rolling Volatility of Log Returns', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '04_volatility_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVolatility Statistics:\")\n",
    "print(f\"Average 30-day volatility: {df['Volatility_30'].mean():.6f}\")\n",
    "print(f\"Maximum 30-day volatility: {df['Volatility_30'].max():.6f}\")\n",
    "print(f\"Date of max volatility: {df['Volatility_30'].idxmax()}\")\n",
    "print(f\"âœ“ Figure saved: 04_volatility_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high volatility periods\n",
    "volatility_threshold = df['Volatility_30'].quantile(0.90)\n",
    "high_vol_periods = df[df['Volatility_30'] > volatility_threshold]\n",
    "\n",
    "print(f\"\\nHigh Volatility Periods (>90th percentile = {volatility_threshold:.6f}):\")\n",
    "print(f\"Total high volatility days: {len(high_vol_periods)}\")\n",
    "print(f\"\\nTop 10 highest volatility periods:\")\n",
    "print(high_vol_periods.nlargest(10, 'Volatility_30')[['Price', 'Volatility_30', 'Log_Returns']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dc311",
   "metadata": {},
   "source": [
    "## 8. Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Plot ACF and PACF for log returns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "plot_acf(df['Log_Returns'].dropna(), lags=40, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF) - Log Returns', fontsize=12, fontweight='bold')\n",
    "\n",
    "plot_pacf(df['Log_Returns'].dropna(), lags=40, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF) - Log Returns', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '05_autocorrelation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAutocorrelation Insights:\")\n",
    "print(\"- ACF shows correlation structure in log returns\")\n",
    "print(\"- Significant spikes indicate memory/dependence in the series\")\n",
    "print(f\"âœ“ Figure saved: 05_autocorrelation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9833d",
   "metadata": {},
   "source": [
    "## 9. Focus Period: 2014-2022\n",
    "\n",
    "Focus on recent period with major geopolitical events for change point analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data from 2014 onwards\n",
    "df_recent = df['2014-01-01':].copy()\n",
    "\n",
    "print(f\"Recent period dataset:\")\n",
    "print(f\"Date range: {df_recent.index.min()} to {df_recent.index.max()}\")\n",
    "print(f\"Total observations: {len(df_recent)}\")\n",
    "print(f\"\\nPrice statistics (2014-2022):\")\n",
    "print(df_recent['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec098fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot recent period with annotations for major events\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "ax.plot(df_recent.index, df_recent['Price'], linewidth=1.2, color='steelblue')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Brent Oil Price (USD/barrel)', fontsize=12)\n",
    "ax.set_title('Brent Oil Prices: 2014-2022 (Focus Period for Change Point Analysis)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate major known events\n",
    "events = [\n",
    "    ('2014-11-27', 'OPEC Maintains\\nProduction', 'red'),\n",
    "    ('2016-11-30', 'OPEC Cut\\nAgreement', 'green'),\n",
    "    ('2018-05-08', 'US Iran\\nSanctions', 'orange'),\n",
    "    ('2019-09-14', 'Saudi Aramco\\nAttacks', 'red'),\n",
    "    ('2020-03-09', 'Saudi-Russia\\nPrice War', 'darkred'),\n",
    "    ('2020-04-20', 'WTI Negative\\nPrices', 'purple'),\n",
    "    ('2022-02-24', 'Russia-Ukraine\\nInvasion', 'red'),\n",
    "]\n",
    "\n",
    "for date, label, color in events:\n",
    "    ax.axvline(pd.Timestamp(date), color=color, linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "    ax.text(pd.Timestamp(date), ax.get_ylim()[1]*0.95, label, \n",
    "            rotation=90, verticalalignment='top', fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '06_focus_period_2014_2022.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ“ Figure saved: 06_focus_period_2014_2022.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa62f04",
   "metadata": {},
   "source": [
    "## 10. Summary: Time Series Properties & Modeling Implications\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Non-Stationarity**: Raw prices are non-stationary (ADF test confirms). This requires:\n",
    "   - Working with log returns for stationarity\n",
    "   - Or modeling level shifts in prices directly via change point detection\n",
    "\n",
    "2. **Volatility Clustering**: Clear evidence of periods where high volatility follows high volatility\n",
    "   - Suggests modeling both mean (Î¼) and variance (Ïƒ) changes\n",
    "   - GARCH-type effects present\n",
    "\n",
    "3. **Heavy Tails**: Log returns show kurtosis > 0, indicating more extreme values than normal distribution\n",
    "   - May need Student-t distribution instead of Normal in some models\n",
    "   - Extreme events are more common than normal distribution predicts\n",
    "\n",
    "4. **Multiple Regime Shifts**: Visual inspection shows several distinct price regimes\n",
    "   - 2014-2016: Oil crash from ~$110 to ~$30\n",
    "   - 2016-2019: Recovery and stabilization\n",
    "   - 2020: COVID crash and recovery\n",
    "   - 2022: Ukraine war spike\n",
    "\n",
    "### Modeling Implications for Bayesian Change Point Analysis:\n",
    "\n",
    "- **Use log returns** for better statistical properties (stationarity)\n",
    "- **Model both Î¼ and Ïƒ changes** to capture volatility regime shifts\n",
    "- **Consider multiple change points** - single change point model will be too simplistic\n",
    "- **Normal likelihood** is reasonable starting point, but be aware of heavy tails\n",
    "- **Prior selection**: Use wide priors initially; data is informative enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for modeling\n",
    "df_recent.to_csv('../data/processed_brent_prices_2014_2022.csv')\n",
    "print(\"Processed data saved to: ../data/processed_brent_prices_2014_2022.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TASK 1 EDA COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š All figures saved to: {REPORTS_DIR.absolute()}\")\n",
    "print(\"\\nGenerated figures:\")\n",
    "print(\"  1. 01_brent_oil_prices_full_series.png\")\n",
    "print(\"  2. 02_moving_averages.png\")\n",
    "print(\"  3. 03_log_returns_analysis.png\")\n",
    "print(\"  4. 04_volatility_analysis.png\")\n",
    "print(\"  5. 05_autocorrelation.png\")\n",
    "print(\"  6. 06_focus_period_2014_2022.png\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Build Bayesian Change Point model in PyMC\")\n",
    "print(\"2. Associate detected change points with researched events\")\n",
    "print(\"3. Quantify impact of each major event\")\n",
    "print(\"4. Develop interactive dashboard for visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
